{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some experiments with OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import io\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "\n",
    "from PIL import Image as PImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions to convert between PIL and OpenCV image types\n",
    "\n",
    "def tocv(pil):\n",
    "  return np.array(pil)\n",
    "\n",
    "def topil(cv):\n",
    "  return PImage.fromarray(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open image from url\n",
    "response = urllib.request.urlopen(\"https://raw.githubusercontent.com/PGDV-5200-2025F-A/silhouettes/refs/heads/main/imgs/00_original/01360.jpg\")\n",
    "image_data = io.BytesIO(response.read())\n",
    "img = PImage.open(image_data)\n",
    "\n",
    "# this makes the largest edge of the image be 480\n",
    "img.thumbnail((480, 480))\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold\n",
    "\n",
    "Turn color/gray image into black and white\n",
    "\n",
    "Doc: https://docs.opencv.org/4.x/db/d8e/tutorial_threshold.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opencv functions take raw pixel arrays and not PIL images ðŸ¤·\n",
    "\n",
    "img_cv = tocv(img)\n",
    "\n",
    "ret, img_thold_cv = cv2.threshold(cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY), 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "display(topil(img_thold_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erode / Dilate\n",
    "\n",
    "Reduces / Expands white regions on the image, respectively.\n",
    "\n",
    "By applying complementary erode/dilate operations you can get rid of gaps and concave parts of an image.\n",
    "\n",
    "Doc: https://docs.opencv.org/4.x/db/df6/tutorial_erosion_dilatation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this sets up the shape and size of the erosion filter\n",
    "eksize = 2\n",
    "ekernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (2 * eksize + 1, 2 * eksize + 1), (eksize, eksize))\n",
    "\n",
    "dksize = 3\n",
    "dkernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (2 * dksize + 1, 2 * dksize + 1), (dksize, dksize))\n",
    "\n",
    "eroded_cv = cv2.erode(img_thold_cv, ekernel)\n",
    "dilated_cv = cv2.dilate(eroded_cv, dkernel)\n",
    "\n",
    "display(topil(dilated_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Outline\n",
    "\n",
    "The function for this is called `findContours()`.\n",
    "\n",
    "Docs: https://docs.opencv.org/4.x/d4/d73/tutorial_py_contours_begin.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [(220,0,0),(0,220,0),(0,0,220),(220,220,0),(0,220,220),(220,0,220)]\n",
    "\n",
    "draw_cv = cv2.cvtColor(dilated_cv.copy(), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(image=dilated_cv, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "if contours:\n",
    "  for idx,con in enumerate(contours):\n",
    "    cv2.drawContours(draw_cv, [con], 0, colors[idx%len(colors)], 2)\n",
    "\n",
    "display(PImage.fromarray(draw_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contour objects\n",
    "\n",
    "are just lists of x,y coordinates, but for some reason opencv adds a mysterious dimension to them.\n",
    "\n",
    "Instead of this:\n",
    "\n",
    "```python\n",
    "[\n",
    "  [x0,y0], [x1,y1], [x2,y2], ...\n",
    "]\n",
    "```\n",
    "\n",
    "We get this (double array around points):\n",
    "```python\n",
    "[\n",
    "  [[x0,y0]], [[x1,y1]], [[x2,y2]], ...\n",
    "]\n",
    "```\n",
    "\n",
    "We can fix it by using the `squeeze()` function which gets rid of superfluous dimensions in arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we want the first contour, this will turn it into a plain list of (x,y) coordinates\n",
    "contours[0].squeeze().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contour Area\n",
    "\n",
    "The `contourArea()` function gives the area of a contour. Useful when trying to find the largest contour in an image.\n",
    "\n",
    "Docs: https://docs.opencv.org/4.x/dd/d49/tutorial_py_contour_features.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.contourArea(contours[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "\n",
    "I used this function to filter the silhouette contours. Contours with points touching the edges of the image, or contours larger than 80% of the image area, or contours smaller than 5% of the image area, are not valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour_is_valid(c, h, w, m=1):\n",
    "  for p in c:\n",
    "    x, y = p[0]\n",
    "    if x < m or x > w - m - 1 or y < m or y > h - m - 1:\n",
    "      return False\n",
    "  return (cv2.contourArea(c) < 0.80 * h * w) and (cv2.contourArea(c) > 0.05 * h * w)\n",
    "\n",
    "contour_is_valid(contours[0], img.size[1], img.size[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [(220,0,0),(0,220,0),(0,0,220),(220,220,0),(0,220,220),(220,0,220)]\n",
    "\n",
    "draw_cv = img_cv.copy()\n",
    "\n",
    "contours, hierarchy = cv2.findContours(image=dilated_cv, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "valid_contours = [con for con in contours if contour_is_valid(con, img.size[1], img.size[0])]\n",
    "\n",
    "for idx,con in enumerate(valid_contours):\n",
    "  cv2.drawContours(draw_cv, [con], 0, colors[idx%len(colors)], 2)\n",
    "\n",
    "display(PImage.fromarray(draw_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Points\n",
    "\n",
    "Not sure if these will help, necessarily, but was something I thought about in terms of extracting features from images.\n",
    "\n",
    "Docs: https://docs.opencv.org/4.x/db/d27/tutorial_py_table_of_contents_feature2d.html\n",
    "\n",
    "### SIFT\n",
    "\n",
    "Docs: https://docs.opencv.org/4.x/da/df5/tutorial_py_sift_intro.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cv = tocv(img)\n",
    "\n",
    "draw_cv = img_cv.copy()\n",
    "\n",
    "gray_cv = cv2.cvtColor(img_cv, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "sift = cv2.SIFT_create(32)\n",
    "kp = sift.detect(gray_cv, None)\n",
    " \n",
    "cv2.drawKeypoints(draw_cv, kp, draw_cv, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "topil(draw_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAST\n",
    "\n",
    "Docs: https://docs.opencv.org/4.x/df/d0c/tutorial_py_fast.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cv = tocv(img)\n",
    "\n",
    "draw_cv = img_cv.copy()\n",
    "\n",
    "gray_cv = cv2.cvtColor(img_cv, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "fast = cv2.FastFeatureDetector_create(threshold=80)\n",
    "kp = fast.detect(gray_cv, None)\n",
    "\n",
    "cv2.drawKeypoints(draw_cv, kp, draw_cv, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "topil(draw_cv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "5020",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
